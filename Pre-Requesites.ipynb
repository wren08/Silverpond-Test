{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Prerequirements for the Deep Learning Workshop\n",
    "\n",
    "In this notebook we have some exercises that contain concepts largely unrelated to deep learning but are used frequently through-out the workshop. We would like to confirm understanding of these techniques by completing this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Tuples and Lists\n",
    "\n",
    "We use tuples frequently as a way to store and receive various lists of arguments. Python has the capability to _destructure_ tuples and lists, and this turns out to often by quite convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: **Constructing tuples**: Tuples are built typically using the `,` operator. For example, `a = 1,2`.\n",
    "\n",
    "You may like to use the `type` inbuilt function to determine if you're completing these exercises correctly.\n",
    "\n",
    "- (1.1) Construct a tuple containing two elements.\n",
    "\n",
    "- (1.2) Construct a tuple containing 1 element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "# Exercise 1.1:\n",
    "a = (1,2)\n",
    "print(type(a))\n",
    "\n",
    "# Exercise 1.2:\n",
    "b = (1,)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2: **Deconstructing tuples**: (aka _De-tupling_ aka _Unpacking_) Tuples (and lists!) can be _deconstructed_ using standard assignment operators. Destructuring here refers to picking out individual components of the tuple. This can also be performed using standard python indexing, but sometimes destructuring may be more simple.\n",
    "\n",
    "For the purposes of these exercises, let:\n",
    "\n",
    "```\n",
    "a = (1, 2, \"Hello\")\n",
    "```\n",
    "\n",
    "- (2.1) Using only the variable `a` as so-defined, define three new variables that take on each of the values in the tuple.\n",
    "\n",
    "- (2.2) Again using only the variable `a`, define a single new variable that takes on the value `\"Hello\"`. (Hint: Oftentimes we will use the special variable name `_` to indicate that we do not care about a value.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Hello\n",
      "Hello\n"
     ]
    }
   ],
   "source": [
    "a = (1, 2, \"Hello\")\n",
    "\n",
    "# TODO:\n",
    "# Exercise 2.1:\n",
    "a_1, a_2, a_3 = a\n",
    "print(a_1)\n",
    "print(a_2)\n",
    "print(a_3)\n",
    "\n",
    "# Exercise 2.2:\n",
    "_, _, b = a\n",
    "print(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3: **Lists and Destructuring**: We typically build a list with square brackets, like `a = [1,2]`. Can we do the same de-structuring operations with a list?\n",
    "\n",
    "- (3.1) Repeat exercises 1.1, 1.2, 2.1 and 2.2 using lists instead of tuples. Does everything just work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "1\n",
      "2\n",
      "Hello\n",
      "Hello\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "\n",
    "# Exercise 3.1\n",
    "\n",
    "#list with two elements\n",
    "l_1 = [1,2]\n",
    "print(type(l_1))\n",
    "\n",
    "#list with one element\n",
    "l_2 = [1]\n",
    "print(type(l_2))\n",
    "\n",
    "#three new variables\n",
    "b, c, d = a\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "\n",
    "\n",
    "#one variable\n",
    "_, _, e = a\n",
    "print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Slicing\n",
    "\n",
    "Slicing is a great tool. It allows us to access ranges of elements in lists/tuples/arrays in a compact fashion. It also is supported on numpy arrays, which we typically use quite often. We won't attempt to cover _all_ the details of Python slicing here, only the parts that we use in the workshop.\n",
    "\n",
    "In order to understand slicing, note that in Python (and most programming languages) when we index into an array, we start at `0`. So given:\n",
    "\n",
    "```\n",
    "a = [2, 3, 5, 7, 11, 13] # Prime numbers ...\n",
    "```\n",
    "\n",
    "Then `a[0] == 2` and `a[2] == 5`.\n",
    "\n",
    "Exercise 4: **Slicing**.\n",
    "\n",
    "- (4.1) Confirm the above statements.\n",
    "\n",
    "- (4.2) We can also use negative numbers to pick out elements starting from the end of the list. What item does `-1` return?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "\n",
    "new_list = [2, 3, 5, 7, 11, 13]\n",
    "# Exercise 4.1\n",
    "print(new_list[0])\n",
    "print(new_list[2])\n",
    "\n",
    "# Exercise 4.2\n",
    "\n",
    "#return the last element\n",
    "print(new_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5: **Selecting segments with slicing**: While we can pick out specific values with indexing, slicing lets us pick out specific resgions of our list.\n",
    "\n",
    "The syntax for a slice is `m:n` for some integers `m` and `n`. We use it like `a[0:2]` to pick out all the elements from `a` starting with `0` up to but not including `2`.\n",
    "\n",
    "- (5.1) Before running the above slice, can you guess how many elements will be returned? Test your guess.\n",
    "\n",
    "- (5.2) Try other numbers in the slice operation. What happens? Can you generate an Exception? What happens when you try negative numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n",
      "[5, 7, 11, 13]\n",
      "[13, 11]\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "\n",
    "# Exercise 5.1\n",
    "\n",
    "#two elements\n",
    "print(new_list[0:2])\n",
    "\n",
    "# Exercise 5.2\n",
    "print(new_list[2:len(new_list)])\n",
    "\n",
    "#negative numbers\n",
    "\n",
    "#last two elements\n",
    "print(new_list[:-3:-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: `numpy` Arrays\n",
    "\n",
    "Numpy is used to manage data coming in and going out of TensorFlow. There are a few concepts in numpy and TensorFlow that will be used frequently. In particular, let us look at the \"Shape\".\n",
    "\n",
    "Consider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([2, 3, 5, 7, 11, 13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can get the _shape_ with `.shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the shape is hinting that the array can actually be multi-dimensional. And indeed, they can, and it turns out to be very useful!\n",
    "\n",
    "Exercise 6: **Shapes**.\n",
    "\n",
    "- (6.1) Use the function [`np.ones`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html) to construct a multi-dimensional array of size `1280x1024x3` (i.e. a standard RGB image of height 1280, width 1024 and 3 colour channels). Check the shape with `.shape`.\n",
    "\n",
    "- (6.2) *Multi-dimensional slicing* We can perform a slice on this variable, say `b`, like `b[:, :, 1]` to pick out the second RGB dimension (Green) from this faux-image. Confirm this by doing it, and checking the shape. Try out other multi-dimensional slices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 1024, 3)\n",
      "(1280, 1024)\n",
      "(1280, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 6.1\n",
    "img = np.ones((1280, 1024, 3))\n",
    "print(img.shape)\n",
    "\n",
    "# Exercise 6.2\n",
    "b = img[:, :, 1]\n",
    "print(b.shape)\n",
    "\n",
    "#slcing to pick out the first dimension\n",
    "r = img[:, :, 0]\n",
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: TensorFlow, The Computation Graph & The Session\n",
    "\n",
    "Here we will not use any deep-learning functionality in TensorFlow, but we will introduce two key ideas.\n",
    "\n",
    "The first is the _Computation Graph_. This is a global object that we construct indirectly by defining various operations, variables, and placeholders via the TensorFlow API.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(9)\n",
    "c = tf.add(tf.square(a), b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above establishes the computation graph to consider the expression:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "a &= 2 \\\\\n",
    "b &= 9 \\\\\n",
    "c &= a^2 + b\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In diagram form, the flow of data for this expression looks like:\n",
    "\n",
    "![](images/graph.png)\n",
    "\n",
    "\n",
    "Clearly, TensorFlow is very verbose! And `c` doesn't even take on a concrete value, evidently (we'll get into this when we discuss the _Session_).\n",
    "\n",
    "We can simplify it a bit (if we are only interested in the value of `c`), by utilising operator overloading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = 2\n",
    "b = 9\n",
    "c = tf.square(a) + b\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 7: **Building graphs by using operations**: We refer to the process of definine such expressions as \"building the graph\". TensorFlow supports many mathematical operations (after all, we're going to do deep learning later!) but for now, stick to the ones you know to build up some interesting TensorFlow graphs. Note that the result of all of the expressions is a _Tensor_.\n",
    "\n",
    "- (7.1) Define your own mathematical expression using the TensorFlow operations:\n",
    "\n",
    "    - [tf.add](https://www.tensorflow.org/api_docs/python/tf/add)\n",
    "    - [tf.square](https://www.tensorflow.org/api_docs/python/tf/square)\n",
    "    - [tf.subtract](https://www.tensorflow.org/api_docs/python/tf/subtract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_1:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "\n",
    "# Exercise 7.1\n",
    "m = tf.constant(2)\n",
    "n = tf.constant(5)\n",
    "p = tf.add(m, tf.square(tf.subtract(n, m)))\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this is well-and-good, but we're interested in _evaluating_ such expression. To perform evaluation, we need to use a _Session_. This sets up a manager of all the resources we may need. This tends to be useful if we are performing computations across GPUs, where we don't want to worry about memory-management: TensorFlow takes care of it for us.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Note: We could also use the `resource` form here, like:\n",
    "#\n",
    "# with tf.Session() as sess:\n",
    "#     a = 2\n",
    "#     b = 9\n",
    "#     c = tf.square(a) + b\n",
    "#     c_value = sess.run(c)\n",
    "#\n",
    "# but it turns out to be more convenient to use the \n",
    "# `InteractiveSession` one here, as it let's us re-use\n",
    "# the session between cells.\n",
    "\n",
    "\n",
    "\n",
    "a = 2\n",
    "b = 9\n",
    "c = tf.square(a) + b\n",
    "\n",
    "c_value = sess.run(c)\n",
    "\n",
    "print(c_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we've computed the value finally! We often call this \"evaluating\" the graph. Note that TensorFlow only computes those values (which it calls nodes) that are required for the particular value you are seeking. So for example, `c` depends on `a` and `b`, so those values are required.\n",
    "\n",
    "Exercise 8: **Sessions and running them**.\n",
    "\n",
    "- (8.1) Run your own expressions with `sess.run`.\n",
    "\n",
    "- (8.2) Try defining two different equations for `c` and `d`, then running them with `sess.run([c, d])`. What is the return value here? How does it relate to what we've done with tuples/lists above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "[11, -7]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 8.1\n",
    "p_value = sess.run(p)\n",
    "\n",
    "print(p_value)\n",
    "\n",
    "\n",
    "# Exercise 8.2\n",
    "c = tf.add(a, b)\n",
    "d = tf.subtract(a, b)\n",
    "print(sess.run([c, d]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5: Tensorflow - Feeding in values with `feed_dict`\n",
    "\n",
    "So now we have the ability to compute arbitrary math functions.\n",
    "\n",
    "Consider now that we'd like to set up a graph to compute the following expression:\n",
    "\n",
    "$$\n",
    "c(x, y) = x^2 + y\n",
    "$$\n",
    "\n",
    "Note how this differs notationally from our earlier example. Here we are calling out that `c` depends on `x` and `y`, and that these variables need to be provided. In TensorFlow we accomplish this with the `feed_dict` argument to `sess.run( c, feed_dict=... )`, and [_placeholders_](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "Let's see an example of a placeholder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.int32, shape=(1,))\n",
    "c = a + 2\n",
    "\n",
    "a_value, = sess.run(c, feed_dict={ a: (9,)})\n",
    "\n",
    "print(a_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 9: **Placeholders and feed dicts**. We can set up expressions with values that we later fill-in by using placeholders. The `feed_dict` argument to [`Session.run( ... )`](https://www.tensorflow.org/api_docs/python/tf/Session) lets us provide values for the placeholders by constructing a dictionary like `{ placholderVariable: placeholderValue }`. Note that matching up shapes is crucial, and TensorFlow doesn't let us provide a value that isn't in an array of some kind!\n",
    "\n",
    "- (9.1) Using placeholders, define a graph where the value $c(x,y)$ can be computed by providing the value for two placeholders named `x` and `y`, and compute them for a few different values of `x` and `y` using the feed_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "\n",
    "# Exercise 9.1\n",
    "x = tf.placeholder(tf.int32, shape = (1,))\n",
    "y = tf.placeholder(tf.int32, shape = (1,))\n",
    "q = x + y\n",
    "\n",
    "q_value, = sess.run(q, feed_dict = {x: (2, ), y: (3,)})\n",
    "print(q_value)\n",
    "\n",
    "X = [0, 1, 2]\n",
    "Y = [2, 3, 4]\n",
    "\n",
    "for xi in X:\n",
    "    for yi in Y:\n",
    "        q_value, = sess.run(q, feed_dict = {x: (xi, ), y: (yi, )})\n",
    "        print(q_value)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it!\n",
    "\n",
    "Thanks for completing the pre-requistites! See you at the workshop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
